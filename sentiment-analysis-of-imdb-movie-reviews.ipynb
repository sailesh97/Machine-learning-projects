{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "Sentiment Analysis of IMDB Movie Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1424638f5259100af9f9a5c1b05bd23cf5b71e51"
   },
   "source": [
    "Import the nltk and necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IMDB Dataset.csv']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "import re\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "be1b642cce343f7a8f68f8c91f7c50372cdf4381"
   },
   "source": [
    "Import the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "4c593c17588723c0b0b0f19851cb70a8447ced76",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>If you like original gut wrenching laughter yo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "5  Probably my all-time favorite movie, a story o...  positive\n",
       "6  I sure would like to see a resurrection of a u...  positive\n",
       "7  This show was an amazing, fresh & innovative i...  negative\n",
       "8  Encouraged by the positive comments about this...  negative\n",
       "9  If you like original gut wrenching laughter yo...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_data=pd.read_csv('../input/IMDB Dataset.csv')\n",
    "print(imdb_data.shape)\n",
    "imdb_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1ad3773974351ed9bdf389b2847d7475b36c2295"
   },
   "source": [
    "Exploratery data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "7f11c83b1320c8982b36889145f7f770563674a8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>49582</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Loved today's show!!! It was a variety and not...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review sentiment\n",
       "count                                               50000     50000\n",
       "unique                                              49582         2\n",
       "top     Loved today's show!!! It was a variety and not...  positive\n",
       "freq                                                    5     25000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "453c3fd238f62ab8f649eb01771817e25bc0c77d"
   },
   "source": [
    "Finding the number of counts of each sentiment reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "cb6bb97b0f851947dcf341a1de5708a1f2bc64c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    25000\n",
       "negative    25000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_data['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f61964573faababe1f7897b77d32815a24954d2f"
   },
   "source": [
    "Import the reviews and sentiments from IMDB dataset and split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "d3aaabff555e07feb11c72cc3a6e457615975ffe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000,) (40000,)\n",
      "(10000,) (10000,)\n"
     ]
    }
   ],
   "source": [
    "reviews=np.array(imdb_data['review'])\n",
    "sentiments=np.array(imdb_data['sentiment'])\n",
    "                    \n",
    "train_reviews=reviews[:40000]\n",
    "train_sentiments=sentiments[:40000]\n",
    "test_reviews=reviews[40000:]\n",
    "test_sentiments=sentiments[40000:]\n",
    "print(train_reviews.shape,train_sentiments.shape)\n",
    "print(test_reviews.shape,test_sentiments.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "90da29c3b79f46f41d7391a2a116065b616d0fac"
   },
   "source": [
    "Text preprocessing or text normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "f000c43d91f68f6668539f089c6a54c5ce3bd819"
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import spacy\n",
    "import re,string,unicodedata\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.stem import LancasterStemmer,WordNetLemmatizer\n",
    "tokenizer=ToktokTokenizer()\n",
    "stopword_list=nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "328b6e5977da3e055ad4b2e11a31e5e12ccf3b16"
   },
   "source": [
    "Removing html strips characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "6f6fcafbdadcdcb0c164e37d71fb9d1623f74d0a"
   },
   "outputs": [],
   "source": [
    "def strip_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub('\\[[^]]*\\]', '', text)\n",
    "\n",
    "def denoise_text(text):\n",
    "    text = strip_html(text)\n",
    "    text = remove_between_square_brackets(text)\n",
    "    return text\n",
    "imdb_data['review']=imdb_data['review'].apply(denoise_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a7a26c7a72e20bf8847e13729de3a0a28d30204d"
   },
   "source": [
    "Remove accented characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "af8f99b95306ba4060e42576d612a5ed9dfea301"
   },
   "outputs": [],
   "source": [
    "def remove_accented_chars(text):\n",
    "    text=unicodedata.normalize('NFKD',text).encode('ascii','ignore').decode('utf-8','ignore')\n",
    "    return text\n",
    "imdb_data['review']=imdb_data['review'].apply(remove_accented_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0a9c3b857dc616c7ac82ce8af7d39607162c15cf"
   },
   "source": [
    "Expand contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "5cb57ee6f7087b9ae0592c01a220a638955c2137",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CONTRACTION_MAP = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \n",
    "                   \"can't've\": \"cannot have\", \"'cause\": \"because\", \"could've\": \"could have\", \n",
    "                   \"couldn't\": \"could not\", \"couldn't've\": \"could not have\",\"didn't\": \"did not\", \n",
    "                   \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \n",
    "                   \"hadn't've\": \"had not have\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \n",
    "                   \"he'd\": \"he would\", \"he'd've\": \"he would have\", \"he'll\": \"he will\", \n",
    "                   \"he'll've\": \"he he will have\", \"he's\": \"he is\", \"how'd\": \"how did\", \n",
    "                   \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\", \n",
    "                   \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \n",
    "                   \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \n",
    "                   \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\", \n",
    "                   \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \n",
    "                   \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \n",
    "                   \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \n",
    "                   \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \n",
    "                   \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \n",
    "                   \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \n",
    "                   \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \n",
    "                   \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\",\n",
    "                   \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \n",
    "                   \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \n",
    "                   \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \n",
    "                   \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \n",
    "                   \"this's\": \"this is\",\n",
    "                   \"that'd\": \"that would\", \"that'd've\": \"that would have\",\"that's\": \"that is\", \n",
    "                   \"there'd\": \"there would\", \"there'd've\": \"there would have\",\"there's\": \"there is\", \n",
    "                   \"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \n",
    "                   \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \n",
    "                   \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \n",
    "                   \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \n",
    "                   \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \n",
    "                   \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\", \n",
    "                   \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \n",
    "                   \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \n",
    "                   \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \n",
    "                   \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \n",
    "                   \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \n",
    "                   \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \n",
    "                   \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n",
    "                   \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                   \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \n",
    "                   \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\" } \n",
    "\n",
    "def expand_contractions(text, contraction_mapping=CONTRACTION_MAP):\n",
    "    \n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())), \n",
    "                                      flags=re.IGNORECASE|re.DOTALL)\n",
    "    def expand_match(contraction):\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = contraction_mapping.get(match)\\\n",
    "                                if contraction_mapping.get(match)\\\n",
    "                                else contraction_mapping.get(match.lower())                       \n",
    "        expanded_contraction = first_char+expanded_contraction[1:]\n",
    "        return expanded_contraction\n",
    "        \n",
    "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
    "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
    "    return expanded_text\n",
    "imdb_data['review']=imdb_data['review'].apply(expand_contractions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "88117b74761d1047924d6d70f76642faa0e706ac"
   },
   "source": [
    "Removing special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "219da72b025121fd98081df50ae0fcaace10cc9d"
   },
   "outputs": [],
   "source": [
    "def remove_special_characters(text, remove_digits=False):\n",
    "    pattern=r'[^a-zA-z0-9\\s]' if not remove_digits else r'[a-zA-z\\s]'\n",
    "    text=re.sub(pattern,'',text)\n",
    "    return text\n",
    "imdb_data['review']=imdb_data['review'].apply(remove_special_characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3b66eeabd5b7b8c251f8b8ddf331140a64bcd514"
   },
   "source": [
    "Text stemming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "2295f2946e0ab74c220ad538d0e7adc04d23f697"
   },
   "outputs": [],
   "source": [
    "def simple_stemmer(text):\n",
    "    ps=nltk.porter.PorterStemmer()\n",
    "    text= ' '.join([ps.stem(word) for word in text.split()])\n",
    "    return text\n",
    "imdb_data['review']=imdb_data['review'].apply(simple_stemmer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e83107e4a281d84d7ae42b4e2c8d81b7ece438e4"
   },
   "source": [
    "Removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "5dbff82b4d2d188d8777b273a75d8ac714d38885"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'were', 'on', 'have', 'yourself', \"it's\", 'where', 'just', 'be', 'should', 'can', 'ma', 'most', 'few', 'of', 'in', \"mustn't\", 'an', 'this', 'any', 's', 'aren', 'mightn', 'weren', \"weren't\", 'are', 'it', 'more', \"didn't\", 'some', 'having', \"needn't\", 'doing', 'through', 'its', 'her', 'only', 'yourselves', 'themselves', 'hers', 'll', 'what', 'needn', 'while', 'his', 'who', \"doesn't\", 'both', 'by', 't', \"you've\", 'is', 'why', 'now', 'isn', 'about', 're', \"hasn't\", 'same', 'when', 'wouldn', 'itself', 'will', 'didn', \"hadn't\", 'before', 'too', \"you'll\", 'a', 'because', \"won't\", 'you', \"wouldn't\", 'until', 'or', \"she's\", 'above', 'we', 'ourselves', 've', 'does', 'himself', 'here', 'couldn', 'so', 'between', 'very', 'for', 'ain', 'being', 'was', 'wasn', 'no', 'yours', \"you're\", \"should've\", 'own', 'do', 'off', \"shan't\", 'that', 'again', 'am', 'as', 'don', 'o', 'herself', \"that'll\", 'hasn', 'those', 'shouldn', 'under', 'haven', 'they', 'nor', 'm', 'won', 'once', 'not', 'theirs', 'their', 'd', 'your', 'the', \"shouldn't\", 'below', \"haven't\", 'into', 'than', 'had', 'been', 'him', \"isn't\", 'me', 'against', 'she', \"mightn't\", 'such', 'i', \"you'd\", 'and', 'during', 'shan', 'down', 'these', \"couldn't\", 'hadn', 'my', 'ours', 'out', 'further', 'how', 'doesn', 'after', 'has', \"wasn't\", 'with', 'he', 'mustn', 'myself', 'up', \"aren't\", 'then', 'our', 'at', 'to', 'which', 'over', 'from', 'all', \"don't\", 'but', 'them', 'if', 'each', 'other', 'y', 'whom', 'there', 'did'}\n"
     ]
    }
   ],
   "source": [
    "stop=set(stopwords.words('english'))\n",
    "print(stop)\n",
    "\n",
    "def remove_stopwords(text, is_lower_case=False):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    if is_lower_case:\n",
    "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    else:\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text\n",
    "imdb_data['review']=imdb_data['review'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b35e7499291173119ed42287deac6f0cd96516e1"
   },
   "source": [
    "Normalize train reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "b20c242bd091929ca896ea2c6e936ca00efe6ecf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one review ha mention watch 1 Oz episod hook right thi exactli happen meth first thing struck Oz wa brutal unflinch scene violenc set right word GO trust thi show faint heart timid thi show pull punch regard drug sex violenc hardcor classic use wordit call OZ nicknam given oswald maximum secur state penitentari focus mainli emerald citi experiment section prison cell glass front face inward privaci high agenda Em citi home manyaryan muslim gangsta latino christian italian irish moreso scuffl death stare dodgi deal shadi agreement never far awayi would say main appeal show due fact goe show would dare forget pretti pictur paint mainstream audienc forget charm forget romanceoz doe mess around first episod ever saw struck nasti wa surreal could say wa readi watch develop tast Oz got accustom high level graphic violenc violenc injustic crook guard sold nickel inmat kill order get away well manner middl class inmat turn prison bitch due lack street skill prison experi watch Oz may becom comfort uncomfort viewingthat get touch darker side'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_train_reviews=imdb_data.review[:40000]\n",
    "norm_train_reviews[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d69462bb209a66cff86376dc8481d0c0140d894d"
   },
   "source": [
    "Normalize test reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "c5d0d38bd9976150367e9d75f3b933774c96a1ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'first want say lean liber polit scale found movi offens manag watch whole doggon disgrac film thi movi bring low origin idea ye wa origin thu 2 star instead 1 film writer uncr onli come thi act wa horribl charact unlik part lead ladi stori good qualiti made bf sort bad guy see mayb miss someth knowh wa earth relev charact movi shell ani money thi garbag almost wish peta would come rescu thi aw offens movi form protest disgust say anymor'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_test_reviews=imdb_data.review[40000:]\n",
    "norm_test_reviews[40000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1c2a872ffcb6b8076fdbbba641af12081b6022ef"
   },
   "source": [
    "Bags of words model used to convert categorical data to numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "35cf9dcefb40b2dc520c5b0d559695324c46cc04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW_cv_train: (40000, 1927678)\n",
      "BOW_cv_test: (10000, 1927678)\n"
     ]
    }
   ],
   "source": [
    "cv=CountVectorizer(min_df=0,max_df=1,binary=False,ngram_range=(1,2))\n",
    "cv_train_reviews=cv.fit_transform(norm_train_reviews)\n",
    "cv_test_reviews=cv.transform(norm_test_reviews)\n",
    "\n",
    "print('BOW_cv_train:',cv_train_reviews.shape)\n",
    "print('BOW_cv_test:',cv_test_reviews.shape)\n",
    "#vocab=cv.get_feature_names()-toget feature names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "52371868f05ff9cf157280c5acf0f5bc71ee176d"
   },
   "source": [
    "TFIDF model used to convert categorical data to  numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "afe6de957339921e05a6faeaf731f2272fd31946",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tfidf_train: (40000, 1927678)\n",
      "Tfidf_test: (10000, 1927678)\n"
     ]
    }
   ],
   "source": [
    "tv=TfidfVectorizer(min_df=0,max_df=1,use_idf=True,ngram_range=(1,2),sublinear_tf=True)\n",
    "tv_train_reviews=tv.fit_transform(norm_train_reviews)\n",
    "tv_test_reviews=tv.transform(norm_test_reviews)\n",
    "print('Tfidf_train:',tv_train_reviews.shape)\n",
    "print('Tfidf_test:',tv_test_reviews.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "803e92b25faa738b10928a91de72d177d8dddf85"
   },
   "source": [
    "LabelBinarizer used to convert catrgorical data to numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "60f5d496ce4109d1cdbf08f4284d4d26efd93922"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "lb=LabelBinarizer()\n",
    "sentiment_data=lb.fit_transform(imdb_data['sentiment'])\n",
    "print(sentiment_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "21a80c94fb42e14391c627710c5d796c40aa7dde"
   },
   "source": [
    "Split the sentiment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "ca1e4cc917265ac98a72c37cffe57f27e9897408"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "train_sentiments=sentiment_data[:40000]\n",
    "test_sentiments=sentiment_data[40000:]\n",
    "print(train_sentiments)\n",
    "print(test_sentiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4633a5146ebf6eea7e4fe5f4db73809b6bb47382"
   },
   "source": [
    "Supervised learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "4564be551fb8f0d44619596a78cc21caaa99247e"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d5e45fdc9d062a5b9b9dd665ffe732776e196953"
   },
   "source": [
    "Logistic regression and Stochastic Gradient descent Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "142d007421900550079a12ae8655bcae678ebaad"
   },
   "outputs": [],
   "source": [
    "lr=LogisticRegression(penalty='l2',max_iter=100,C=1,random_state=32)\n",
    "svm=SGDClassifier(loss='hinge',n_iter=100,random_state=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ad410d9f81ef7f6ecf2f5efe9237e5804d7af2b7"
   },
   "source": [
    "Logistic regression for Bag of words model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "07eb6d52eb32469e3be82e90af636d598a7b7c27"
   },
   "source": [
    "fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "52ad86935b76117f97b79e6672a3ba12352b9461"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=32, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_bow=lr.fit(cv_train_reviews,train_sentiments)\n",
    "lr_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "39f3896e259325ba62fe3a743c49479fa508cd3a"
   },
   "source": [
    "predict the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "51178f1b71f55e147f9dc8b2c8fccab1f784e0aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_bow_predict=lr.predict(cv_test_reviews)\n",
    "lr_bow_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ac2ec8353acb5e0f548e1e4a590fbe6f34f4a686"
   },
   "source": [
    "print the classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "f89c7e7a6136d08790ffbf6bc4d0d05455f8555a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.65      0.78      0.71      4993\n",
      "    Negative       0.72      0.58      0.64      5007\n",
      "\n",
      "   micro avg       0.68      0.68      0.68     10000\n",
      "   macro avg       0.68      0.68      0.67     10000\n",
      "weighted avg       0.68      0.68      0.67     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_bow_report=classification_report(test_sentiments,lr_bow_predict,target_names=['Positive','Negative'])\n",
    "print(lr_bow_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0d2e5ddcd69ff0fb52f05f17fc74a86e1b5e5b61"
   },
   "source": [
    "plot the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "a36c058e834938559b7202f2142e61423a613b7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2898 2109]\n",
      " [1116 3877]]\n"
     ]
    }
   ],
   "source": [
    "cm_bow=confusion_matrix(test_sentiments,lr_bow_predict,labels=[1,0])\n",
    "print(cm_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "45680f45634336898d3f73e0ff3670b9bf8fa664"
   },
   "source": [
    "From the confusion matrix, we can conclude that out of 5007 reviews, 2898 reviews are correctly predict as positive\n",
    "and out of 4993 reviews,3877 reviews correctly predicted as negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8de75ee65e91dd2996123a3c085209fb5e0c55ff"
   },
   "source": [
    "Logistic Regression for TFIDF model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3a5882eb970439e8da0ac489578d7b7df5f6991f"
   },
   "source": [
    "fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "2ded3caa4728e19793b711855ac0b0e94473412d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=32, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_tfidf=lr.fit(tv_train_reviews,train_sentiments)\n",
    "lr_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9676a1be242c339ce04fb104578db61c41ba5349"
   },
   "source": [
    "predict the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "77f5c7462276d37b35620a69e2e5871c2b0e2d85"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=32, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_tfidf_predict=lr.predict(tv_test_reviews)\n",
    "lr_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "74912a1f4f21e404f11a7b44a80029ff2037f68d"
   },
   "source": [
    "plot the classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "a133175b631ab993f81e837db616548941473fdf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.69      0.69      0.69      4993\n",
      "    negative       0.69      0.68      0.69      5007\n",
      "\n",
      "   micro avg       0.69      0.69      0.69     10000\n",
      "   macro avg       0.69      0.69      0.69     10000\n",
      "weighted avg       0.69      0.69      0.69     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_tfidf_report=classification_report(test_sentiments,lr_tfidf_predict,target_names=['positive','negative'])\n",
    "print(lr_tfidf_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ec7ca249c27ce0bba94872c374539c32c4615ba6"
   },
   "source": [
    "Plot the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "fa37d39d1cd4dbae92a03550bac04a692f5c93be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3459 1534]\n",
      " [1578 3429]]\n"
     ]
    }
   ],
   "source": [
    "cm_tfidf=confusion_matrix(test_sentiments,lr_tfidf_predict)\n",
    "print(cm_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8d8fefee5c2278ef53267b30acc2819807b2aaee"
   },
   "source": [
    "From the confusion matrix, we can predict that out of 4993 reviews, 3459 reviews are correctly predicted as positive\n",
    "and out of 5007 reviews, 3429 reviews are correctly predicted as negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8fde9753386e3593dc27c4e88e02bdc38462a018"
   },
   "source": [
    "SVM for Bag of words model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "41374b26011a37ac2f4f985b86373be1a3c6bc77"
   },
   "source": [
    "fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_uuid": "2211a9e97682195a0372b33e4da7267aad8548db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
       "       n_iter=100, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "       power_t=0.5, random_state=32, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_bow=svm.fit(cv_train_reviews,train_sentiments)\n",
    "svm_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e9a7a973591c1d3cabaa1a47c57fa029d3752bab"
   },
   "source": [
    "predict the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_uuid": "1a5ab738e04f0f9082c8d6ade6c2148cc398f8f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_bow_pred=svm.predict(cv_test_reviews)\n",
    "svm_bow_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b1bd245f50902ad87ca28e48cbce64ec6a16ec5a"
   },
   "source": [
    "plot the classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_uuid": "d112bc5b4944330b567e19a7e04544a9a459f238"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.65      0.73      0.69      4993\n",
      "    negative       0.70      0.62      0.65      5007\n",
      "\n",
      "   micro avg       0.67      0.67      0.67     10000\n",
      "   macro avg       0.68      0.67      0.67     10000\n",
      "weighted avg       0.68      0.67      0.67     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_bow_report=classification_report(test_sentiments,svm_bow_pred,target_names=['positive','negative'])\n",
    "print(svm_bow_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "705fd8ae8bb5e6925852fffc906b6ffd769dbac0"
   },
   "source": [
    "plot the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_uuid": "49cde912705acbaef90d7a269cd27ea8a2815f03"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3644, 1349],\n",
       "       [1924, 3083]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_bow=confusion_matrix(test_sentiments,svm_bow_pred)\n",
    "cm_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c72c8e59112b822a317c21426ecb98ad702e7ca5"
   },
   "source": [
    "From the confusion matrix, we can predict that out of 4993 reviews, 3644 reviews are correctly predicted as positive\n",
    "and out of 5007 reviews, 3083 reviews are correctly predicted as negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "25b3801a56ef7ae734fd46275ec3b25301527c30"
   },
   "source": [
    "SVM for TFIDF model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c7d641d59f83f61039d779be68172867299ad182"
   },
   "source": [
    "fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_uuid": "cec6f6150b3cfa832f92108448b7f12e301ff3d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
       "       n_iter=100, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "       power_t=0.5, random_state=32, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_tf=svm.fit(tv_train_reviews,train_sentiments)\n",
    "svm_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1da41ff0fb881e7894e95a4e8a3b82246fcd9023"
   },
   "source": [
    "predict the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_uuid": "8425278e1894b5b141d7e9872914df598831ca0f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_tf_pred=svm.predict(tv_test_reviews)\n",
    "svm_tf_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e167a192870d3b0103e20f499e2847415b5913f3"
   },
   "source": [
    "plot the classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_uuid": "bfdd0a38b901446a093e6e17686fff70923b8e7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       1.00      0.02      0.04      4993\n",
      "    negative       0.51      1.00      0.67      5007\n",
      "\n",
      "   micro avg       0.51      0.51      0.51     10000\n",
      "   macro avg       0.75      0.51      0.36     10000\n",
      "weighted avg       0.75      0.51      0.36     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_tf_report=classification_report(test_sentiments,svm_tf_pred,target_names=['positive','negative'])\n",
    "print(svm_tf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_uuid": "ac1429d171c6d3248b58a6958a43d0c086756845"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 104, 4889],\n",
       "       [   0, 5007]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_tf_report=confusion_matrix(test_sentiments,svm_tf_pred)\n",
    "cm_tf_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fb19b2f0335fcafc142e0fca86c9fba49a3d95e7"
   },
   "source": [
    "From the confusion matrix,as we can predict that out of 4993 reviews, 104 reviews are correctly predicted as positive\n",
    "and out of 5007 reviews,5007 reviews are correctly predicted as negative."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
